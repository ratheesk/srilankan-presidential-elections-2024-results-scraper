{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the webpage!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://results.elections.gov.lk/\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"Successfully fetched the webpage!\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Live Sri Lanka Presidential Election Results 2024 | Real-Time Results\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML content\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Print the title of the webpage to confirm parsing\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting All Island Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'candidate': 'ANURA KUMARA DISSANAYAKE', 'party': 'NPP', 'total_votes': 5634915, 'preferences': 105264, 'total': 5740179}\n",
      "{'candidate': 'SAJITH PREMADASA', 'party': 'SJB', 'total_votes': 4363035, 'preferences': 167867, 'total': 4530902}\n"
     ]
    }
   ],
   "source": [
    "# Extracting All Island Final Results\n",
    "all_island_results_section = soup.find('h4', text='All Island final Result').find_next('table')\n",
    "\n",
    "all_island_results = []\n",
    "for row in all_island_results_section.find_all('tr')[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 0:\n",
    "        candidate = columns[0].text.strip()\n",
    "        party = columns[1].text.strip()\n",
    "        total_votes = columns[2].text.strip().replace(',', '')\n",
    "        preferences = columns[3].text.strip().replace(',', '')\n",
    "        total = columns[4].text.strip().replace(',', '')\n",
    "\n",
    "        all_island_results.append({\n",
    "            'candidate': candidate,\n",
    "            'party': party,\n",
    "            'total_votes': int(total_votes),\n",
    "            'preferences': int(preferences),\n",
    "            'total': int(total)\n",
    "        })\n",
    "\n",
    "# Display the extracted All Island results\n",
    "for result in all_island_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting All Island Preference Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'candidate': 'ANURA KUMARA DISSANAYAKE', 'party': 'NPP', 'preferences': 105264}\n",
      "{'candidate': 'SAJITH PREMADASA', 'party': 'SJB', 'preferences': 167867}\n"
     ]
    }
   ],
   "source": [
    "# Extracting All Island Preference Results\n",
    "preference_results_section = soup.find('h4', text='All Island Preference Result').find_next('table')\n",
    "\n",
    "preference_results = []\n",
    "for row in preference_results_section.find_all('tr')[1:]:  # Skip the header row\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 0:\n",
    "        candidate = columns[0].text.strip()\n",
    "        party = columns[1].text.strip()\n",
    "        preferences = columns[2].text.strip().replace(',', '')\n",
    "\n",
    "        preference_results.append({\n",
    "            'candidate': candidate,\n",
    "            'party': party,\n",
    "            'preferences': int(preferences)\n",
    "        })\n",
    "\n",
    "# Display the extracted Preference results\n",
    "for result in preference_results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting All Island Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted All Island Results:\n",
      "Candidate: ANURA KUMARA DISSANAYAKE, Party: NPP, Votes Received: 5634915, Percentage: 42.31%\n",
      "Candidate: SAJITH PREMADASA, Party: SJB, Votes Received: 4363035, Percentage: 32.76%\n",
      "Candidate: RANIL WICKREMESINGHE, Party: IND16, Votes Received: 2299767, Percentage: 17.27%\n",
      "Candidate: NAMAL RAJAPAKSA, Party: SLPP, Votes Received: 342781, Percentage: 2.57%\n",
      "Candidate: ARIYANETHIRAN PAKKIYASELVAM, Party: IND9, Votes Received: 226343, Percentage: 1.7%\n"
     ]
    }
   ],
   "source": [
    "# Extracting All Island Results\n",
    "all_island_results_section = soup.find('h4', text='All Island Results')\n",
    "\n",
    "# Check if the section is found\n",
    "if all_island_results_section is not None:\n",
    "    all_island_results_section = all_island_results_section.find_next('table')\n",
    "\n",
    "    all_island_results = []\n",
    "    for row in all_island_results_section.find_all('tr')[1:]:  # Skip the header row\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) > 0:\n",
    "            candidate = columns[0].text.strip()\n",
    "            party = columns[1].text.strip()\n",
    "            votes_received = columns[2].text.strip().replace(',', '')\n",
    "            percentage = columns[3].text.strip()\n",
    "\n",
    "            all_island_results.append({\n",
    "                'candidate': candidate,\n",
    "                'party': party,\n",
    "                'votes_received': int(votes_received),\n",
    "                'percentage': percentage\n",
    "            })\n",
    "\n",
    "    # Display the extracted All Island results\n",
    "    print(\"\\nExtracted All Island Results:\")\n",
    "    for result in all_island_results[:5]:  # Print first 5 results\n",
    "        print(f\"Candidate: {result['candidate']}, Party: {result['party']}, Votes Received: {result['votes_received']}, Percentage: {result['percentage']}\")\n",
    "else:\n",
    "    print(\"Section 'All Island Results' not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Island Results saved to 'all_island_results.csv'\n",
      "Preference Results saved to 'preference_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine the results into a single DataFrame\n",
    "final_results_df = pd.DataFrame(all_island_results)\n",
    "preference_results_df = pd.DataFrame(preference_results)\n",
    "\n",
    "# Save All Island Results to CSV\n",
    "final_results_df.to_csv('all_island_results.csv', index=False)\n",
    "\n",
    "# Save Preference Results to CSV\n",
    "preference_results_df.to_csv('preference_results.csv', index=False)\n",
    "\n",
    "# Optionally, print confirmation messages\n",
    "print(\"All Island Results saved to 'all_island_results.csv'\")\n",
    "print(\"Preference Results saved to 'preference_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Votes: 13319616\n",
      "Rejected Votes: 300300\n",
      "Total Polled: 13619916\n",
      "Total Electors: 17140354\n"
     ]
    }
   ],
   "source": [
    "# Extracting Voting Details\n",
    "voting_details_section = soup.find(text='Valid Votes').find_parent('table')\n",
    "\n",
    "# Initialize a dictionary to hold voting details\n",
    "voting_details = {}\n",
    "\n",
    "# Extract details from the voting details section\n",
    "if voting_details_section is not None:\n",
    "    rows = voting_details_section.find_all('tr')\n",
    "\n",
    "    for row in rows:\n",
    "        columns = row.find_all('td')\n",
    "        if len(columns) > 0:\n",
    "            label = columns[0].text.strip()\n",
    "            value = columns[1].text.strip().replace(',', '')\n",
    "            voting_details[label] = int(value)\n",
    "\n",
    "# Display the extracted voting details\n",
    "for key, value in voting_details.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting details saved to 'voting_details.csv'\n"
     ]
    }
   ],
   "source": [
    "# Convert voting details to a DataFrame\n",
    "voting_details_df = pd.DataFrame(list(voting_details.items()), columns=['Detail', 'Value'])\n",
    "\n",
    "# Save Voting Details to CSV\n",
    "voting_details_df.to_csv('voting_details.csv', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Voting details saved to 'voting_details.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## District Preference Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "District preference results saved to 'district_preference_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# List of districts to scrape preference data\n",
    "districts = [\n",
    "    \"Colombo\", \"Gampaha\", \"Kalutara\", \"Mahanuwara\", \"Matale\", \n",
    "    \"Nuwaraeliya\", \"Galle\", \"Matara\", \"Hambantota\", \"Jaffna\", \n",
    "    \"Vanni\", \"Batticaloa\", \"Digamadulla\", \"Trincomalee\", \"Kurunegala\", \n",
    "    \"Puttalam\", \"Anuradhapura\", \"Polonnaruwa\", \"Badulla\", \n",
    "    \"Monaragala\", \"Ratnapura\", \"Kegalle\"\n",
    "]\n",
    "\n",
    "# Initialize a list to hold preference results for all districts\n",
    "all_district_results = []\n",
    "\n",
    "# Loop through each district to extract preference data\n",
    "for district in districts:\n",
    "    # Construct the URL for each district\n",
    "    url = f\"https://results.elections.gov.lk/district_preference.php?district={district}\"\n",
    "    \n",
    "    # Make a request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extracting preference results for each district\n",
    "        preference_results_section = soup.find('h4', text=f'District Preference Result of {district}').find_next('table')\n",
    "\n",
    "        # Extract the data from the table\n",
    "        if preference_results_section is not None:\n",
    "            for row in preference_results_section.find_all('tr')[1:]:  # Skip the header row\n",
    "                columns = row.find_all('td')\n",
    "                if len(columns) > 0:\n",
    "                    candidate = columns[0].text.strip()\n",
    "                    party = columns[1].text.strip()\n",
    "                    preferences = columns[2].text.strip().replace(',', '')\n",
    "\n",
    "                    all_district_results.append({\n",
    "                        'district': district,\n",
    "                        'candidate': candidate,\n",
    "                        'party': party,\n",
    "                        'preferences': int(preferences)\n",
    "                    })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {district}\")\n",
    "\n",
    "# Convert the results to a DataFrame and save to CSV\n",
    "district_results_df = pd.DataFrame(all_district_results)\n",
    "district_results_df.to_csv('district_preference_results.csv', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"District preference results saved to 'district_preference_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postal votes results saved to 'postal_votes_results.csv'\n"
     ]
    }
   ],
   "source": [
    "# List of districts to scrape postal votes data\n",
    "districts = [\n",
    "    \"Colombo\", \"Gampaha\", \"Kalutara\", \"Mahanuwara\", \"Matale\", \n",
    "    \"Nuwaraeliya\", \"Galle\", \"Matara\", \"Hambantota\", \"Jaffna\", \n",
    "    \"Vanni\", \"Batticaloa\", \"Digamadulla\", \"Trincomalee\", \"Kurunegala\", \n",
    "    \"Puttalam\", \"Anuradhapura\", \"Polonnaruwa\", \"Badulla\", \n",
    "    \"Monaragala\", \"Ratnapura\", \"Kegalle\"\n",
    "]\n",
    "\n",
    "# Initialize a list to hold postal votes results for all districts\n",
    "all_postal_votes_results = []\n",
    "\n",
    "# Loop through each district to extract postal votes data\n",
    "for district in districts:\n",
    "    # Construct the URL for postal votes in each district\n",
    "    url = f\"https://results.elections.gov.lk/division_results.php?district={district}&pd_division=Postal%20Votes\"\n",
    "    \n",
    "    # Make a request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract postal votes for each district\n",
    "        postal_votes_section = soup.find('h4', text=f'Election Result for {district} District: Postal Votes').find_next('table')\n",
    "\n",
    "        # Extract the data from the table\n",
    "        if postal_votes_section is not None:\n",
    "            for row in postal_votes_section.find_all('tr')[1:]:  # Skip the header row\n",
    "                columns = row.find_all('td')\n",
    "                if len(columns) > 0:\n",
    "                    candidate = columns[0].text.strip()\n",
    "                    party = columns[1].text.strip()\n",
    "                    votes_received = columns[2].text.strip().replace(',', '')\n",
    "\n",
    "                    all_postal_votes_results.append({\n",
    "                        'district': district,\n",
    "                        'candidate': candidate,\n",
    "                        'party': party,\n",
    "                        'votes_received': int(votes_received)\n",
    "                    })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {district}\")\n",
    "\n",
    "# Convert the results to a DataFrame and save to CSV\n",
    "postal_votes_df = pd.DataFrame(all_postal_votes_results)\n",
    "postal_votes_df.to_csv('postal_votes_results.csv', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Postal votes results saved to 'postal_votes_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polling divisions results saved to 'polling_divisions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to hold polling divisions for all districts\n",
    "all_polling_divisions = []\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://results.elections.gov.lk\"\n",
    "\n",
    "# Loop through each district to extract polling divisions data\n",
    "for district in districts:\n",
    "    # Construct the URL for each district\n",
    "    url = f\"https://results.elections.gov.lk/district_results.php?district={district}\"\n",
    "    \n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract polling divisions from the section with the h4 heading \"Polling Divisions\"\n",
    "        polling_divisions_section = soup.find('h4', text='Polling Divisions')\n",
    "        \n",
    "        if polling_divisions_section is not None:\n",
    "            polling_divisions_links = polling_divisions_section.find_next('div', class_='mt-3').find_all('a', class_='result-link')\n",
    "            \n",
    "            # Extract the data from the links\n",
    "            for link in polling_divisions_links:\n",
    "                division_name = link.find('p', class_='fw-bold').text.strip()\n",
    "                \n",
    "                all_polling_divisions.append({\n",
    "                    'district': district,\n",
    "                    'polling_division': division_name,\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {district}\")\n",
    "\n",
    "# Convert the results to a DataFrame and save to CSV\n",
    "polling_divisions_df = pd.DataFrame(all_polling_divisions)\n",
    "polling_divisions_df.to_csv('polling_divisions.csv', index=False)\n",
    "\n",
    "# Confirmation message\n",
    "print(\"Polling divisions results saved to 'polling_divisions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read the CSV file containing district and polling division data\n",
    "polling_divisions_df = pd.read_csv('polling_divisions.csv')\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://results.elections.gov.lk/division_results.php\"\n",
    "\n",
    "# Initialize a list to hold the election result data\n",
    "election_results = []\n",
    "\n",
    "# Function to scrape data from each polling division\n",
    "def scrape_polling_division_data(district, polling_division):\n",
    "    # Construct the URL for the polling division\n",
    "    url = f\"{base_url}?district={district}&pd_division={polling_division.replace(' ', '%20')}\"\n",
    "\n",
    "    # Send a request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the h4 title for the polling division\n",
    "        # Set title format based on whether it's postal votes or not\n",
    "        if polling_division == \"Postal Votes\":\n",
    "            h4_title = soup.find('h4', text=f'Election Result for {district} District: {polling_division}')\n",
    "        else:\n",
    "            h4_title = soup.find('h4', text=f'Election Result for Polling Division : {polling_division}')\n",
    "\n",
    "        if h4_title:\n",
    "            # Find the table containing the results (assuming it's the first table after the h4)\n",
    "            results_table = h4_title.find_next('table')\n",
    "\n",
    "            if results_table:\n",
    "                # Extract rows from the table\n",
    "                for row in results_table.find_all('tr')[1:]:  # Skip the header row\n",
    "                    columns = row.find_all('td')\n",
    "                    if len(columns) > 0:\n",
    "                        candidate = columns[0].text.strip()\n",
    "                        party = columns[1].text.strip()\n",
    "                        votes = columns[2].text.strip().replace(',', '')\n",
    "                        percentage = columns[3].text.strip()\n",
    "\n",
    "                        # Append the data to the election_results list\n",
    "                        election_results.append({\n",
    "                            'district': district,\n",
    "                            'polling_division': polling_division,\n",
    "                            'candidate': candidate,\n",
    "                            'party': party,\n",
    "                            'votes': int(votes),\n",
    "                            'percentage': percentage\n",
    "                        })\n",
    "        else:\n",
    "            print(f\"Title not found for {polling_division}\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {polling_division} in {district}\")\n",
    "\n",
    "# Loop through each polling division and scrape the data\n",
    "for index, row in polling_divisions_df.iterrows():\n",
    "    district = row['district']\n",
    "    polling_division = row['polling_division']\n",
    "    print(f\"Scraping data for {polling_division} in {district}...\")\n",
    "    scrape_polling_division_data(district, polling_division)\n",
    "\n",
    "# Save the election results to a CSV file\n",
    "with open('polling_division_results.csv', mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=['district', 'polling_division', 'candidate', 'party', 'votes', 'percentage'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(election_results)\n",
    "\n",
    "print(\"Election results saved to 'polling_division_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for Postal Votes in Colombo...\n",
      "Scraping data for ColomboNorth in Colombo...\n",
      "Scraping data for ColomboCentral in Colombo...\n",
      "Scraping data for Borella in Colombo...\n",
      "Scraping data for ColomboEast in Colombo...\n",
      "Scraping data for ColomboWest in Colombo...\n",
      "Scraping data for Dehiwala in Colombo...\n",
      "Scraping data for Ratmalana in Colombo...\n",
      "Scraping data for Kolonnawa in Colombo...\n",
      "Scraping data for Kotte in Colombo...\n",
      "Scraping data for Kaduwela in Colombo...\n",
      "Scraping data for Avissawella in Colombo...\n",
      "Scraping data for Homagama in Colombo...\n",
      "Scraping data for Maharagama in Colombo...\n",
      "Scraping data for Kesbewa in Colombo...\n",
      "Scraping data for Moratuwa in Colombo...\n",
      "Scraping data for Postal Votes in Gampaha...\n",
      "Scraping data for Wattala in Gampaha...\n",
      "Scraping data for Negambo in Gampaha...\n",
      "Scraping data for Katana in Gampaha...\n",
      "Scraping data for Divulapitiya in Gampaha...\n",
      "Scraping data for Mirigama in Gampaha...\n",
      "Scraping data for Minuwangoda in Gampaha...\n",
      "Scraping data for Attanagalla in Gampaha...\n",
      "Scraping data for Gampaha in Gampaha...\n",
      "Scraping data for Ja-Ela in Gampaha...\n",
      "Scraping data for Mahara in Gampaha...\n",
      "Scraping data for Dompe in Gampaha...\n",
      "Scraping data for Biyagama in Gampaha...\n",
      "Scraping data for Kelaniya in Gampaha...\n",
      "Scraping data for Postal Votes in Kalutara...\n",
      "Scraping data for Panadura in Kalutara...\n",
      "Scraping data for Bandaragama in Kalutara...\n",
      "Scraping data for Horana in Kalutara...\n",
      "Scraping data for Bulathsinhala in Kalutara...\n",
      "Scraping data for Matugama in Kalutara...\n",
      "Scraping data for Kalutara in Kalutara...\n",
      "Scraping data for Beruwala in Kalutara...\n",
      "Scraping data for Agalawatta in Kalutara...\n",
      "Scraping data for Postal Votes in Mahanuwara...\n",
      "Scraping data for Galagedara in Mahanuwara...\n",
      "Scraping data for Harispattuwa in Mahanuwara...\n",
      "Scraping data for Patadumbara in Mahanuwara...\n",
      "Scraping data for Udadumbara in Mahanuwara...\n",
      "Scraping data for Teldeniya in Mahanuwara...\n",
      "Scraping data for Kundasale in Mahanuwara...\n",
      "Scraping data for Hewahata in Mahanuwara...\n",
      "Scraping data for Senkadagala in Mahanuwara...\n",
      "Scraping data for Mahanuwara in Mahanuwara...\n",
      "Scraping data for Yatinuwara in Mahanuwara...\n",
      "Scraping data for Udunuwara in Mahanuwara...\n",
      "Scraping data for Gampola in Mahanuwara...\n",
      "Scraping data for Nawalapitiya in Mahanuwara...\n",
      "Scraping data for Postal Votes in Matale...\n",
      "Scraping data for Dambulla in Matale...\n",
      "Scraping data for Laggala in Matale...\n",
      "Scraping data for Matale in Matale...\n",
      "Scraping data for Rattota in Matale...\n",
      "Scraping data for Postal Votes in Nuwaraeliya...\n",
      "Scraping data for N.E.Maskeliya in Nuwaraeliya...\n",
      "Scraping data for Kothmale in Nuwaraeliya...\n",
      "Scraping data for Hanguranketha in Nuwaraeliya...\n",
      "Scraping data for Walapane in Nuwaraeliya...\n",
      "Scraping data for Postal Votes in Galle...\n",
      "Scraping data for Balapitiya in Galle...\n",
      "Scraping data for Ambalangoda in Galle...\n",
      "Scraping data for Karandeniya in Galle...\n",
      "Scraping data for BentaraElpitiya in Galle...\n",
      "Scraping data for Hiniduma in Galle...\n",
      "Scraping data for Baddegama in Galle...\n",
      "Scraping data for Ratgama in Galle...\n",
      "Scraping data for Galle in Galle...\n",
      "Scraping data for Akmeemana in Galle...\n",
      "Scraping data for Habaraduwa in Galle...\n",
      "Scraping data for Postal Votes in Matara...\n",
      "Scraping data for Deniyaya in Matara...\n",
      "Scraping data for Hakmana in Matara...\n",
      "Scraping data for Akuressa in Matara...\n",
      "Scraping data for Kamburupitiya in Matara...\n",
      "Scraping data for Devinuwara in Matara...\n",
      "Scraping data for Matara in Matara...\n",
      "Scraping data for Weligama in Matara...\n",
      "Scraping data for Postal Votes in Hambantota...\n",
      "Scraping data for Mulkirigala in Hambantota...\n",
      "Scraping data for Beliatta in Hambantota...\n",
      "Scraping data for Tangalle in Hambantota...\n",
      "Scraping data for Tissamaharama in Hambantota...\n",
      "Scraping data for Postal Votes in Jaffna...\n",
      "Scraping data for Kayts in Jaffna...\n",
      "Scraping data for Vadducoddai in Jaffna...\n",
      "Scraping data for Kankesanthurai in Jaffna...\n",
      "Scraping data for Manipay in Jaffna...\n",
      "Scraping data for Kopai in Jaffna...\n",
      "Scraping data for Uduppiddy in Jaffna...\n",
      "Scraping data for Point-Pedro in Jaffna...\n",
      "Scraping data for Chavakachcheri in Jaffna...\n",
      "Scraping data for Nallur in Jaffna...\n",
      "Scraping data for Jaffna in Jaffna...\n",
      "Scraping data for Kilinochchi in Jaffna...\n",
      "Scraping data for Postal Votes in Vanni...\n",
      "Scraping data for Mannar in Vanni...\n",
      "Scraping data for Vavuniya in Vanni...\n",
      "Scraping data for Mulaithivu in Vanni...\n",
      "Scraping data for Postal Votes in Batticaloa...\n",
      "Scraping data for Kalkuda in Batticaloa...\n",
      "Scraping data for Batticaloa in Batticaloa...\n",
      "Scraping data for Paddiruppu in Batticaloa...\n",
      "Scraping data for Postal Votes in Digamadulla...\n",
      "Scraping data for Ampara in Digamadulla...\n",
      "Scraping data for Sammanthurai in Digamadulla...\n",
      "Scraping data for Kalmunai in Digamadulla...\n",
      "Scraping data for Pothuvil in Digamadulla...\n",
      "Scraping data for Postal Votes in Trincomalee...\n",
      "Scraping data for Seruwila in Trincomalee...\n",
      "Scraping data for Trincomalee in Trincomalee...\n",
      "Scraping data for Muthur in Trincomalee...\n",
      "Scraping data for Postal Votes in Kurunegala...\n",
      "Scraping data for Galgamuwa in Kurunegala...\n",
      "Scraping data for Nikaweratiya in Kurunegala...\n",
      "Scraping data for Yapahuwa in Kurunegala...\n",
      "Scraping data for Hiriyala in Kurunegala...\n",
      "Scraping data for Wariyapola in Kurunegala...\n",
      "Scraping data for Paduwasnuwara in Kurunegala...\n",
      "Scraping data for Bingiriya in Kurunegala...\n",
      "Scraping data for Katugampola in Kurunegala...\n",
      "Scraping data for Kuliyapitiya in Kurunegala...\n",
      "Scraping data for Dambadeniya in Kurunegala...\n",
      "Scraping data for Polgahawela in Kurunegala...\n",
      "Scraping data for Kurunegala in Kurunegala...\n",
      "Scraping data for Mawathagama in Kurunegala...\n",
      "Scraping data for Dodangaslanda in Kurunegala...\n",
      "Scraping data for Postal Votes in Puttalam...\n",
      "Scraping data for Puttalam in Puttalam...\n",
      "Scraping data for Anamaduwa in Puttalam...\n",
      "Scraping data for Chillaw in Puttalam...\n",
      "Scraping data for Nattandiya in Puttalam...\n",
      "Scraping data for Wennappuwa in Puttalam...\n",
      "Scraping data for Postal Votes in Anuradhapura...\n",
      "Scraping data for Medawachchiya in Anuradhapura...\n",
      "Scraping data for Horowpathana in Anuradhapura...\n",
      "Scraping data for AnuradhapuraEast in Anuradhapura...\n",
      "Scraping data for AnuradhapuraWest in Anuradhapura...\n",
      "Scraping data for Kalawewa in Anuradhapura...\n",
      "Scraping data for Mihinthale in Anuradhapura...\n",
      "Scraping data for Kekirawa in Anuradhapura...\n",
      "Scraping data for Postal Votes in Polonnaruwa...\n",
      "Scraping data for Minneriya in Polonnaruwa...\n",
      "Scraping data for Medirigiriya in Polonnaruwa...\n",
      "Scraping data for Polonnaruwa in Polonnaruwa...\n",
      "Scraping data for Postal Votes in Badulla...\n",
      "Scraping data for Mahiyangana in Badulla...\n",
      "Scraping data for Wiyaluwa in Badulla...\n",
      "Scraping data for Passara in Badulla...\n",
      "Scraping data for Badulla in Badulla...\n",
      "Scraping data for Haliela in Badulla...\n",
      "Scraping data for Uvaparanagama in Badulla...\n",
      "Scraping data for Welimada in Badulla...\n",
      "Scraping data for Bandarawela in Badulla...\n",
      "Scraping data for Haputhale in Badulla...\n",
      "Scraping data for Postal Votes in Monaragala...\n",
      "Scraping data for Bibila in Monaragala...\n",
      "Scraping data for Moneragala in Monaragala...\n",
      "Scraping data for Wellawaya in Monaragala...\n",
      "Scraping data for Postal Votes in Ratnapura...\n",
      "Scraping data for Eheliyagoda in Ratnapura...\n",
      "Scraping data for Ratnapura in Ratnapura...\n",
      "Scraping data for Pelmadulla in Ratnapura...\n",
      "Scraping data for Balangoda in Ratnapura...\n",
      "Scraping data for Rakwana in Ratnapura...\n",
      "Scraping data for Nivithigala in Ratnapura...\n",
      "Scraping data for Kalawana in Ratnapura...\n",
      "Scraping data for Kolonna in Ratnapura...\n",
      "Scraping data for Postal Votes in Kegalle...\n",
      "Scraping data for Dedigama in Kegalle...\n",
      "Scraping data for Galigamuwa in Kegalle...\n",
      "Scraping data for Kegalle in Kegalle...\n",
      "Scraping data for Rambukkana in Kegalle...\n",
      "Scraping data for Mawanella in Kegalle...\n",
      "Scraping data for Aranayake in Kegalle...\n",
      "Scraping data for Yatiyantota in Kegalle...\n",
      "Scraping data for Ruwanwella in Kegalle...\n",
      "Scraping data for Deraniyagala in Kegalle...\n",
      "Voting details scraping complete and saved to additional_polling_details.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Read the CSV file containing district and polling division data\n",
    "polling_divisions_df = pd.read_csv('polling_divisions.csv')\n",
    "\n",
    "# Base URL\n",
    "base_url = \"https://results.elections.gov.lk/division_results.php\"\n",
    "\n",
    "# Initialize a list to hold the additional details\n",
    "additional_details = []\n",
    "\n",
    "# Function to scrape voting details from each polling division\n",
    "def scrape_voting_details(district, polling_division):\n",
    "    # Construct the URL for the polling division\n",
    "    url = f\"{base_url}?district={district}&pd_division={polling_division.replace(' ', '%20')}\"\n",
    "\n",
    "    # Send a request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Extract voting details (valid votes, rejected votes, etc.)\n",
    "        voting_details_section = soup.find(text='Valid Votes').find_parent('table')\n",
    "        \n",
    "        # Initialize a dictionary to hold voting details\n",
    "        voting_details = {}\n",
    "\n",
    "        # Extract details from the voting details section\n",
    "        if voting_details_section is not None:\n",
    "            rows = voting_details_section.find_all('tr')\n",
    "\n",
    "            for row in rows:\n",
    "                columns = row.find_all('td')\n",
    "                if len(columns) > 0:\n",
    "                    label = columns[0].text.strip()\n",
    "                    value = columns[1].text.strip().replace(',', '')\n",
    "                    voting_details[label] = int(value)\n",
    "\n",
    "            # Append additional data to the additional_details list\n",
    "            additional_details.append({\n",
    "                'district': district,\n",
    "                'polling_division': polling_division,\n",
    "                'valid_votes': voting_details.get('Valid Votes', 0),\n",
    "                'rejected_votes': voting_details.get('Rejected Votes', 0),\n",
    "                'total_polled': voting_details.get('Total Polled', 0),\n",
    "                'total_electors': voting_details.get('Total Electors', 0)\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Voting details table not found for {polling_division} in {district}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {polling_division} in {district}. HTTP Status: {response.status_code}\")\n",
    "\n",
    "# Iterate through the polling divisions and scrape voting details\n",
    "for _, row in polling_divisions_df.iterrows():\n",
    "    district = row['district']\n",
    "    polling_division = row['polling_division']\n",
    "    print(f\"Scraping data for {polling_division} in {district}...\")\n",
    "\n",
    "    scrape_voting_details(district, polling_division)\n",
    "\n",
    "# Convert the list of additional details to a DataFrame and save to CSV\n",
    "additional_details_df = pd.DataFrame(additional_details)\n",
    "additional_details_df.to_csv('additional_polling_details.csv', index=False)\n",
    "\n",
    "print(\"Voting details scraping complete and saved to additional_polling_details.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading NPP.png from https://results.elections.gov.lk/assets/images/symbols/NPP.png\n",
      "Downloading SJB.png from https://results.elections.gov.lk/assets/images/symbols/SJB.png\n",
      "Downloading NPP.png from https://results.elections.gov.lk/assets/images/symbols/NPP.png\n",
      "Downloading SJB.png from https://results.elections.gov.lk/assets/images/symbols/SJB.png\n",
      "Downloading NPP.png from https://results.elections.gov.lk/assets/images/symbols/NPP.png\n",
      "Downloading SJB.png from https://results.elections.gov.lk/assets/images/symbols/SJB.png\n",
      "Downloading IND16.png from https://results.elections.gov.lk/assets/images/symbols/IND16.png\n",
      "Downloading SLPP.png from https://results.elections.gov.lk/assets/images/symbols/SLPP.png\n",
      "Downloading IND9.png from https://results.elections.gov.lk/assets/images/symbols/IND9.png\n",
      "Downloading SLCP.png from https://results.elections.gov.lk/assets/images/symbols/SLCP.png\n",
      "Downloading IND4.png from https://results.elections.gov.lk/assets/images/symbols/IND4.png\n",
      "Downloading IND13.png from https://results.elections.gov.lk/assets/images/symbols/IND13.png\n",
      "Downloading IND12.png from https://results.elections.gov.lk/assets/images/symbols/IND12.png\n",
      "Downloading JPF.png from https://results.elections.gov.lk/assets/images/symbols/JPF.png\n",
      "Downloading IND11.png from https://results.elections.gov.lk/assets/images/symbols/IND11.png\n",
      "Downloading IND5.png from https://results.elections.gov.lk/assets/images/symbols/IND5.png\n",
      "Downloading APP.png from https://results.elections.gov.lk/assets/images/symbols/APP.png\n",
      "Downloading DUNF.png from https://results.elections.gov.lk/assets/images/symbols/DUNF.png\n",
      "Downloading NSSP.png from https://results.elections.gov.lk/assets/images/symbols/NSSP.png\n",
      "Downloading SBP.png from https://results.elections.gov.lk/assets/images/symbols/SBP.png\n",
      "Downloading IND1.png from https://results.elections.gov.lk/assets/images/symbols/IND1.png\n",
      "Downloading SPF.png from https://results.elections.gov.lk/assets/images/symbols/SPF.png\n",
      "Downloading RJA.png from https://results.elections.gov.lk/assets/images/symbols/RJA.png\n",
      "Downloading IND10.png from https://results.elections.gov.lk/assets/images/symbols/IND10.png\n",
      "Downloading IND2.png from https://results.elections.gov.lk/assets/images/symbols/IND2.png\n",
      "Downloading USP.png from https://results.elections.gov.lk/assets/images/symbols/USP.png\n",
      "Downloading JSP.png from https://results.elections.gov.lk/assets/images/symbols/JSP.png\n",
      "Downloading DUA.png from https://results.elections.gov.lk/assets/images/symbols/DUA.png\n",
      "Downloading IND14.png from https://results.elections.gov.lk/assets/images/symbols/IND14.png\n",
      "Downloading SLSP.png from https://results.elections.gov.lk/assets/images/symbols/SLSP.png\n",
      "Downloading AJP.png from https://results.elections.gov.lk/assets/images/symbols/AJP.png\n",
      "Downloading SEP.png from https://results.elections.gov.lk/assets/images/symbols/SEP.png\n",
      "Downloading NIF.png from https://results.elections.gov.lk/assets/images/symbols/NIF.png\n",
      "Downloading IND15.png from https://results.elections.gov.lk/assets/images/symbols/IND15.png\n",
      "Downloading NDF.png from https://results.elections.gov.lk/assets/images/symbols/NDF.png\n",
      "Downloading IND6.png from https://results.elections.gov.lk/assets/images/symbols/IND6.png\n",
      "Downloading UNFF.png from https://results.elections.gov.lk/assets/images/symbols/UNFF.png\n",
      "Downloading IND7.png from https://results.elections.gov.lk/assets/images/symbols/IND7.png\n",
      "Downloading ELPP.png from https://results.elections.gov.lk/assets/images/symbols/ELPP.png\n",
      "Downloading IND8.png from https://results.elections.gov.lk/assets/images/symbols/IND8.png\n",
      "Downloading NSU.png from https://results.elections.gov.lk/assets/images/symbols/NSU.png\n",
      "Downloading SLLP.png from https://results.elections.gov.lk/assets/images/symbols/SLLP.png\n",
      "All images downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL of the page and the folder to save the images\n",
    "url = 'https://results.elections.gov.lk/'\n",
    "symbols_folder = 'symbols'\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(symbols_folder):\n",
    "    os.makedirs(symbols_folder)\n",
    "\n",
    "# Function to download an image\n",
    "def download_image(img_url, folder, img_name):\n",
    "    img_data = requests.get(img_url).content\n",
    "    with open(os.path.join(folder, img_name), 'wb') as handler:\n",
    "        handler.write(img_data)\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all img tags with the symbols\n",
    "    img_tags = soup.find_all('img', src=lambda src: src and 'symbols' in src)\n",
    "\n",
    "    # Loop through each img tag and download the images\n",
    "    for img_tag in img_tags:\n",
    "        img_url = img_tag['src']\n",
    "        img_name = img_url.split('/')[-1]  # Extract the file name\n",
    "\n",
    "        # Handle relative URLs\n",
    "        if not img_url.startswith('http'):\n",
    "            img_url = f\"https://results.elections.gov.lk/{img_url}\"  # Use the appropriate base URL\n",
    "\n",
    "        # Download and save the image\n",
    "        print(f\"Downloading {img_name} from {img_url}\")\n",
    "        download_image(img_url, symbols_folder, img_name)\n",
    "\n",
    "    print('All images downloaded successfully!')\n",
    "else:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
